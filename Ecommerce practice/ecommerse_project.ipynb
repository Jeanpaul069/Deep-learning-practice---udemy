{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.1301098585\n",
      "Train classification rate:  0.92\n",
      "Test classification rate:  0.87\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from process import get_data\n",
    "\n",
    "\n",
    "#logistic regression using softmax\n",
    "#made by brilian from lazy programmer tutorial\n",
    "def y2indicator(y,k):\n",
    "    N = len(y)\n",
    "    ind = np.zeros((N,k))\n",
    "    for i in range(N):\n",
    "        ind[i,y[i]] = 1\n",
    "    return ind\n",
    "\n",
    "X, Y = get_data(\"ecommerce_data.csv\")\n",
    "X, Y = shuffle(X, Y)\n",
    "\n",
    "Y = Y.astype(np.int32)\n",
    "D = X.shape[1]\n",
    "K = len(set(Y))\n",
    "\n",
    "Xtrain = X[:-100]\n",
    "Ytrain = Y[:-100]\n",
    "Ytrain_ind = y2indicator(Ytrain,K)\n",
    "\n",
    "Xtest = X[-100:]\n",
    "Ytest = Y[-100:]\n",
    "Ytest_ind = y2indicator(Ytest,K)\n",
    "\n",
    "W = np.random.randn(D,K)\n",
    "b = np.zeros(K)\n",
    "\n",
    "def softmax(a):\n",
    "    expA = np.exp(a)\n",
    "    return expA/expA.sum(axis=1, keepdims=True)\n",
    "\n",
    "def forward(X, W, b):\n",
    "    return softmax( X.dot(W) + b)\n",
    "\n",
    "def predict(P_Y_X):\n",
    "    return np.argmax(P_Y_X, axis=1) #get class location with 1 value\n",
    "\n",
    "def class_rate(Y, P):\n",
    "    return np.mean(Y == P)\n",
    "\n",
    "def cross_entropy(t, pY):\n",
    "    return np.mean(t*np.log(pY))\n",
    "\n",
    "train_cost =  []\n",
    "a = 0.001 #learning rate\n",
    "\n",
    "for i in range(100000):\n",
    "    pYtrain = forward(Xtrain, W, b)\n",
    "    \n",
    "    ctrain = cross_entropy(Ytrain_ind, pYtrain)\n",
    "    train_cost.append(ctrain)\n",
    "    W -= a*Xtrain.T.dot(pYtrain - Ytrain_ind)\n",
    "    b -=a*(pYtrain - Ytrain_ind).sum(axis=0)\n",
    "    \n",
    "#     if i % 1000 == 0:\n",
    "#         print (i, \"training cost: \", ctrain)\n",
    "        \n",
    "pYtest = forward(Xtest, W, b)\n",
    "ctest = cross_entropy(Ytest_ind, pYtest)\n",
    "print (ctest)\n",
    "\n",
    "print (\"Train classification rate: \", class_rate(Ytrain, predict(pYtrain)))\n",
    "print (\"Test classification rate: \", class_rate(Ytest, predict(pYtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 training cost:  -0.601899875936\n",
      "1001 training cost:  -0.0211404964288\n",
      "2001 training cost:  -0.0187678435637\n",
      "3001 training cost:  -0.0184002416819\n",
      "4001 training cost:  -0.018512252866\n",
      "5001 training cost:  -0.0168833816434\n",
      "6001 training cost:  -0.024812011595\n",
      "7001 training cost:  -0.0150529157483\n",
      "8001 training cost:  -0.0155177521091\n",
      "9001 training cost:  -0.0146342248228\n",
      "-0.0679848948104\n",
      "Train classification rate:  0.97\n",
      "Test classification rate:  0.95\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from process import get_data\n",
    "\n",
    "#neural network\n",
    "#made by brilian from lazy programmer tutorial\n",
    "\n",
    "def y2indicator(y,k):\n",
    "    N = len(y)\n",
    "    ind = np.zeros((N,k))\n",
    "    for i in range(N):\n",
    "        ind[i,y[i]] = 1\n",
    "    return ind\n",
    "\n",
    "X, Y = get_data(\"ecommerce_data.csv\")\n",
    "X, Y = shuffle(X, Y)\n",
    "\n",
    "Y = Y.astype(np.int32)\n",
    "M = 5\n",
    "D = X.shape[1]\n",
    "K = len(set(Y))\n",
    "\n",
    "Xtrain = X[:-100]\n",
    "Ytrain = Y[:-100]\n",
    "Ytrain_ind = y2indicator(Ytrain,K)\n",
    "\n",
    "Xtest = X[-100:]\n",
    "Ytest = Y[-100:]\n",
    "Ytest_ind = y2indicator(Ytest,K)\n",
    "\n",
    "W1 = np.random.randn(D,M)\n",
    "b1 = np.zeros(M)\n",
    "W2 = np.random.randn(M,K)\n",
    "b2 = np.zeros(K)\n",
    "\n",
    "def softmax(a):\n",
    "    expA = np.exp(a)\n",
    "    return expA/expA.sum(axis=1, keepdims=True)\n",
    "\n",
    "def forward(X, W1, b1, W2, b2):\n",
    "    z = np.tanh( X.dot(W1) + b1 )\n",
    "    return softmax( z.dot(W2) + b2 ), z #prediction result, and z\n",
    "\n",
    "def predict(P_Y_X):\n",
    "    return np.argmax(P_Y_X, axis=1) #get class location with 1 value\n",
    "\n",
    "def class_rate(Y, P):\n",
    "    return np.mean(Y == P)\n",
    "\n",
    "def cross_entropy(t, pY):\n",
    "    return np.mean(t*np.log(pY))\n",
    "\n",
    "train_cost =  []\n",
    "a = 0.001 #learning rate\n",
    "\n",
    "for i in range(10000):\n",
    "    pYtrain, Ztrain = forward(Xtrain, W1, b1, W2, b2)\n",
    "    \n",
    "    ctrain = cross_entropy(Ytrain_ind, pYtrain)\n",
    "    train_cost.append(ctrain)\n",
    "    \n",
    "    W2 -= a*Ztrain.T.dot(pYtrain - Ytrain_ind)\n",
    "    b2 -= a*(pYtrain - Ytrain_ind).sum(axis=0)\n",
    "    dZ = (pYtrain - Ytrain_ind).dot(W2.T) * (1 - Ztrain * Ztrain) \n",
    "    W1 -= a*Xtrain.T.dot(dZ)\n",
    "    b1 -= a*dZ.sum(axis=0)\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print (i+1, \"training cost: \", ctrain)\n",
    "        \n",
    "pYtest, Ztest = forward(Xtest, W1, b1, W2, b2)\n",
    "ctest = cross_entropy(Ytest_ind, pYtest)\n",
    "print (ctest)\n",
    "\n",
    "print (\"Train classification rate: \", class_rate(Ytrain, predict(pYtrain)))\n",
    "print (\"Test classification rate: \", class_rate(Ytest, predict(pYtest)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
